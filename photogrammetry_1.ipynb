{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Photogrammetry: Part 1\n",
    "\n",
    "Reading: Szeliski Ch. 7\n",
    "\n",
    "Video Lecture: https://youtu.be/4cS8-b30X54 (Not Mubarak Shah.  His lecture on this topic is incomprehensible and outdated)\n",
    "\n",
    "\n",
    "## Inverting the Camera model\n",
    "\n",
    "You'll recall that back in Project 1, I put a \"bonus\" problem at the bottom.  The question posed was thus:\n",
    "\n",
    "A calibrated camera model is a non-linear function that maps from a 3D coordinate system to a 2D coordinate system.  Can this function be inverted?  Can you, based on a 2D image of an object, recover that object's 3D coordinates?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe0954f6a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "I_1 = plt.imread('campus_stereo_1.jpg')\n",
    "I_2 = plt.imread('campus_stereo_2.jpg')\n",
    "\n",
    "gcp_1 = np.loadtxt('gcp_stereo_1.txt',delimiter=',')\n",
    "gcp_2 = np.loadtxt('gcp_stereo_2.txt',delimiter=',')\n",
    "\n",
    "fig,axs = plt.subplots(nrows=1,ncols=2)\n",
    "axs[0].imshow(I_1)\n",
    "axs[0].plot(gcp_1[:,0],gcp_1[:,1],'ro')\n",
    "\n",
    "axs[1].imshow(I_2)\n",
    "axs[1].plot(gcp_2[:,0],gcp_2[:,1],'ro')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calibrating camera models is easy: we have already produced code that allows us to do it.  You'll remember that the solution to this problem is essentially a *non-linear* least squares problem, the solution of which is the optimal camera pose $\\mathbf{p}_{opt}$:\n",
    "$$\n",
    "\\mathbf{p}_{opt} = \\mathrm{argmin}_{\\mathbf{p}} \\frac{1}{2} \\sum_{i=1}^n \\sum_{j=1}^2 (f(\\mathbf{X}_i,\\mathbf{p})_j - \\mathbf{u}_{ij})^2,\n",
    "$$\n",
    "where $n$ is the number of GCPs, and $f(\\mathbf{X},\\mathbf{p})$ is the projection of real world coordinates $\\mathbf{X}$ into camera coordinates (which depends on the pose $\\mathbf{p}$, and $\\mathbf{u}$ is the pixel coordinates of the equivalent point in the image.\n",
    "\n",
    "Stated plainly, the objective function above corresponds to the situation in which the real world coordinates of ground control points and their locations in the image are known, while the camera parameters are unknown (and are what we are trying to determine).  What we would like to do is to write an objective function for the converse situation, in which the camera parameters are known, the position of a desired object in an image is known, but the real world coordinates are unknown (and are what we are trying to determine).  Such an objective function might look like this:\n",
    "$$\n",
    "\\mathbf{X}_{opt} = \\mathrm{argmin}_{\\mathbf{X}} \\frac{1}{2} \\sum_{j=1}^2 (f(\\mathbf{X},\\mathbf{p})_j - \\mathbf{u}_j)^2,\n",
    "$$\n",
    "where $X_{opt}$ is the position of an object in real world coordinates, $\\mathbf{u}$ is its known coordinates in the image, and $\\mathbf{p}$ is a known camera model.  Unfortunately, using this objective function is doomed to failure.  Why can't this work?  Counting the number of data points, we find that there are two, the two components of $\\mathbf{u}$.  However, the vector $\\mathbf{X}$ has three components.  The system is underdetermined: we can only determine $\\mathbf{X}$ up to a constant scaling factor.  \n",
    "\n",
    "How can we make this system of equations over-determined instead?  We can use more cameras, of course.  How does this affect the objective function: \n",
    "$$\n",
    "\\mathbf{X}_{opt} = \\mathrm{argmin}_{\\mathbf{X}} \\frac{1}{2} \\sum_{i=1}^m \\sum_{j=1}^2 (f(\\mathbf{X},\\mathbf{p}_i)_j - \\mathbf{u}_{ij})^2,\n",
    "$$\n",
    "where $m$ is the number of cameras, $\\mathbf{p}_i$ is the known pose of camera $i$, and $\\mathbf{u}_i$ is the location of the feature of interest in the image corresponding to camera $i$.  As in the case of solving for pose, this problem can be solved using Levenburg-Marquardt.  \n",
    "\n",
    "## Assignment\n",
    "**In the project file you will find two images (campus_stereo_1.jpg and campus_stereo_2.jpg), with two sets of ground control points (gcp_stereo_1.jpg and gcp_stereo_2.jpg).  Optimze a camera model for each image.  Using both these camera models, implement the optimization problem defined above for determining the [Easting,Northing,Elevation] position of the central pivot on the main hall clock.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import scipy.optimize as so\n",
    "\n",
    "# Class for our camera model\n",
    "class Camera(object):\n",
    "    def __init__(self):\n",
    "        self.p = None                   # Pose\n",
    "        self.f = None                   # Focal Length in Pixels\n",
    "        self.c = np.array([None,None])  # Sensor\n",
    "        \n",
    "    def projective_transform(self,x):\n",
    "        \"\"\"  \n",
    "        This function performs the projective transform on generalized coordinates in the camera reference frame.\n",
    "        \"\"\"\n",
    "        focal = self.f\n",
    "        sensor = self.c\n",
    "        \n",
    "        #General Coordinates\n",
    "        gcx = x[0]/x[2]\n",
    "        gcy = x[1]/x[2]\n",
    "        \n",
    "        #Pixel Locations\n",
    "        pu = gcx*focal + sensor[0]/2.\n",
    "        pv = gcy*focal + sensor[1]/2.\n",
    "        \n",
    "        return np.array([pu,pv])\n",
    "      \n",
    "    \n",
    "    def rotational_transform(self,X,pts):\n",
    "        \"\"\"  \n",
    "        This function performs the translation and rotation from world coordinates into generalized camera coordinates.\n",
    "        \"\"\"\n",
    "        \n",
    "        cam_x = X[0]\n",
    "        cam_y = X[1]\n",
    "        cam_z = X[2]\n",
    "        roll = X[3]\n",
    "        pitch = X[4]\n",
    "        yaw = X[5]\n",
    "        \n",
    "        r_axis = np.array([[1, 0, 0], [0, 0,-1], [0, 1, 0]])\n",
    "        r_roll = np.array([[np.cos(roll), 0, -1*np.sin(roll)], [0, 1, 0], [np.sin(roll), 0, np.cos(roll)]])\n",
    "        r_pitch = np.array([[1, 0, 0], [0, np.cos(pitch), np.sin(pitch)], [0, -1*np.sin(pitch), np.cos(pitch)]])\n",
    "        r_yaw = np.array([[np.cos(yaw), -1*np.sin(yaw), 0, 0], [np.sin(yaw), np.cos(yaw), 0, 0], [0, 0, 1, 0]])\n",
    "\n",
    "        T = np.array([[1, 0, 0, -cam_x],[0, 1, 0, -cam_y], [0, 0, 1, -cam_z], [0, 0, 0, 1]])\n",
    "        \n",
    "        C = r_axis @ r_roll @ r_pitch @ r_yaw @ T\n",
    "\n",
    "        return C @ pts\n",
    "    \n",
    "    def rotational_transform(self, X):\n",
    "        \"\"\"\n",
    "        This function performs the translation and rotation from world coordinates into generalized camera coordinates.\n",
    "        \"\"\"\n",
    "\n",
    "        # Unpack pose? could do something different here.\n",
    "        X_cam, Y_cam, Z_cam, azimuth_cam_deg, pitch_cam_deg, roll_cam_deg = self.p\n",
    "\n",
    "        # Make X a set of homogeneous coors\n",
    "        X = np.vstack((X, np.ones(X.shape[1])))\n",
    "\n",
    "        # Convert degrees to radians\n",
    "        azimuth_cam_rad = np.deg2rad(azimuth_cam_deg)\n",
    "        pitch_cam_rad = np.deg2rad(pitch_cam_deg)\n",
    "        roll_cam_rad = np.deg2rad(roll_cam_deg)\n",
    "\n",
    "        translation_vec = [X_cam, Y_cam, Z_cam]\n",
    "        C = self.make_cam_mtx(azimuth_cam_rad, pitch_cam_rad, roll_cam_rad, translation_vec)\n",
    "\n",
    "        return C @ X\n",
    "    \n",
    "    def estimate_pose(self,gcps):\n",
    "        \"\"\"\n",
    "        This function adjusts the pose vector such that the difference between the observed pixel coordinates u_gcp \n",
    "        and the projected pixels coordinates of X_gcp is minimized.\n",
    "        \"\"\"\n",
    "        p_opts = [] # Initial easting, northing, elevation positions\n",
    "        u_gcps = [] # Initial projected u,v coordinates\n",
    "\n",
    "        for gcp in gcps:\n",
    "            pts = gcp[2:5]\n",
    "            # Add homogenous coordinate\n",
    "            pts= np.append(pts, 1)\n",
    "\n",
    "            # Observed pixel coordinates\n",
    "            u_gcp = gcp[0:2]\n",
    "            p_opts.append(pts)\n",
    "            u_gcps.append(u_gcp)\n",
    "    \n",
    "        ave_easting = np.mean([gcp[2] for gcp in gcps])\n",
    "        ave_northing = np.mean([gcp[3] for gcp in gcps])\n",
    "        ave_elevation = np.mean([gcp[4] for gcp in gcps])\n",
    "            \n",
    "        # Initial guess at the pose\n",
    "        p0 = np.array([ave_easting, ave_northing, ave_elevation,90,45,45])\n",
    "        \n",
    "        # print(p0, '\\n', p_opts, '\\n', u_gcps, '\\n')\n",
    "        \n",
    "        # Find the optimal pose minimizing the residual\n",
    "        p_opt = so.least_squares(self.residual, p0, method='lm', args=(p_opts,u_gcps))['x']\n",
    "        \n",
    "        self.p = p_opt\n",
    "        \n",
    "    # Function to transform all gcps into the camera coordinates\n",
    "    def transform_all(self,X_gcp, p):\n",
    "        transformed = []\n",
    "        \n",
    "        for gcp in X_gcp:\n",
    "            # Perform rotational transform on X_gcp\n",
    "            rotated = self.rotational_transform(p, gcp)\n",
    "            \n",
    "            # Project the rotated coordinates to pixel coordinates\n",
    "            projected = self.projective_transform(rotated)\n",
    "            transformed.append(projected)\n",
    "\n",
    "        return transformed\n",
    "    \n",
    "    # Calculate the difference in the estimate projection of X_gcp and actual positions of u_gcp\n",
    "    def residual(self, p0, X_gcp, u_gcp):\n",
    "        all_res = np.array(self.transform_all(X_gcp, p0)) - np.array(u_gcp)\n",
    "        all_res = all_res.ravel()\n",
    "        \n",
    "        return all_res\n",
    "    \n",
    "    def cam_to_ene(self, u):\n",
    "        return self.projective_transform(self.rotational_transform(u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimates the world coordinates of a specific point in multiple images\n",
    "def world_coordinate_estimation(camera_list, u_list):\n",
    "    residuals = np.empty(camera_list.shape[0])\n",
    "\n",
    "    # Computes the residual: X - guess of world coordinates, c - a camera object, u - pixel coordinates of a point\n",
    "    def residual(X, camera, u):\n",
    "        xuv = camera.cam_to_ene(X)\n",
    "        res = xuv - u_list[c]\n",
    "\n",
    "        return res\n",
    "\n",
    "    for c in range(camera_list.shape[0]):\n",
    "        x = camera_list[c].p\n",
    "        residuals[c] = so.least_squares(residual, x, args=(camera_list[c], u_list[c]))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "\n",
    "def get_focallength_x_and_y(img):\n",
    "    with PIL.Image.open(img) as img1:\n",
    "        exif_data = img1._getexif()\n",
    "\n",
    "    focal_35 = exif_data[41989]\n",
    "    try:\n",
    "        x = exif_data[256]\n",
    "        y = exif_data[257]\n",
    "    except:\n",
    "        x = exif_data[40962]\n",
    "        y = exif_data[40963]\n",
    "    focal_length = focal_35/36.0*x\n",
    "    return focal_length, x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "rotational_transform() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-e39a08e6c1af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcam1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcam1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mcam1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate_pose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcp_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mcameras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcam1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-cbad434ac954>\u001b[0m in \u001b[0;36mestimate_pose\u001b[0;34m(self, gcps)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;31m# Find the optimal pose minimizing the residual\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0mp_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mso\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleast_squares\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresidual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_opts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mu_gcps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp_opt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/site-packages/scipy/optimize/_lsq/least_squares.py\u001b[0m in \u001b[0;36mleast_squares\u001b[0;34m(fun, x0, jac, bounds, method, ftol, xtol, gtol, x_scale, loss, f_scale, diff_step, tr_solver, tr_options, jac_sparsity, max_nfev, verbose, args, kwargs)\u001b[0m\n\u001b[1;32m    797\u001b[0m         \u001b[0mx0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_strictly_feasible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m     \u001b[0mf0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    800\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mf0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/site-packages/scipy/optimize/_lsq/least_squares.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'trf'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-cbad434ac954>\u001b[0m in \u001b[0;36mresidual\u001b[0;34m(self, p0, X_gcp, u_gcp)\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;31m# Calculate the difference in the estimate projection of X_gcp and actual positions of u_gcp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mresidual\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_gcp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_gcp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mall_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_gcp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_gcp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0mall_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_res\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-cbad434ac954>\u001b[0m in \u001b[0;36mtransform_all\u001b[0;34m(self, X_gcp, p)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgcp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_gcp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;31m# Perform rotational transform on X_gcp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0mrotated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrotational_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;31m# Project the rotated coordinates to pixel coordinates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: rotational_transform() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "cameras = []\n",
    "cam1 = Camera()\n",
    "f,x,y = get_focallength_x_and_y(\"campus_stereo_1.jpg\")\n",
    "cam1.f = f\n",
    "cam1.c = np.array([x,y])\n",
    "cam1.estimate_pose(gcp_1)\n",
    "cameras.append(cam1)\n",
    "\n",
    "cam2 = Camera()\n",
    "f,x,y = get_focallength_x_and_y(\"campus_stereo_2.jpg\")\n",
    "cam2.f = f\n",
    "cam2.c = np.array([x,y])\n",
    "cam2.estimate_pose(gcp_2)\n",
    "cameras.append(cam2)\n",
    "\n",
    "# broken\n",
    "us = np.array([[1,1],[2,2]])\n",
    "cams = np.array(cameras)\n",
    "world_coordinate_estimation(cams, us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
